name: Scrape data and deploy Cloud run

on:
  schedule:
    - cron: '0 15 * * 1-5'
  workflow_dispatch:

jobs:
  scheduled:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: 2022_code
    steps:
    - name: Check out this repo
      uses: actions/checkout@v3
      with:
        fetch-depth: 0
    - uses: actions/setup-python@v2
      with:
        python-version: '3.10'
        cache: 'pip'
    - run: pip install -r requirements.txt
    - name: Fetch daily data
      run: python scrape_marketprice.py
    - name: Set up Cloud Run
      uses: google-github-actions/setup-gcloud@v0
      with:
        service_account_email: ${{ secrets.GCP_SA_EMAIL }}
        service_account_key: ${{ secrets.GCP_SA_KEY }}
    - name: Deploy to Cloud Run
      run: |-
        gcloud config set run/region us-central1
        gcloud config set project vivid-ocean-350113
        ./deploy.sh
    - name: Commit and push if it changed
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        git commit -m "Latest data: ${timestamp}" ||exit 0
        git push
